{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613b4217-2691-48f9-814c-15ff99dab6d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have tensorflow 2.19.0 and this requires tf-keras package. Please run `pip install tf-keras` or downgrade your tensorflow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retinaface\\commons\\package_utils.py:19\u001b[0m, in \u001b[0;36mvalidate_for_keras3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_keras is already available - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf_keras\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepFace\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deepface\\DeepFace.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m package_utils, folder_utils\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommons\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Logger\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     modeling,\n\u001b[0;32m     22\u001b[0m     representation,\n\u001b[0;32m     23\u001b[0m     verification,\n\u001b[0;32m     24\u001b[0m     recognition,\n\u001b[0;32m     25\u001b[0m     demography,\n\u001b[0;32m     26\u001b[0m     detection,\n\u001b[0;32m     27\u001b[0m     streaming,\n\u001b[0;32m     28\u001b[0m     preprocessing,\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     32\u001b[0m logger \u001b[38;5;241m=\u001b[39m Logger()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deepface\\modules\\modeling.py:16\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# project dependencies\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfacial_recognition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     VGGFace,\n\u001b[0;32m      7\u001b[0m     OpenFace,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     GhostFaceNet,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mface_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     17\u001b[0m     FastMtCnn,\n\u001b[0;32m     18\u001b[0m     MediaPipe,\n\u001b[0;32m     19\u001b[0m     MtCnn,\n\u001b[0;32m     20\u001b[0m     OpenCv,\n\u001b[0;32m     21\u001b[0m     Dlib \u001b[38;5;28;01mas\u001b[39;00m DlibDetector,\n\u001b[0;32m     22\u001b[0m     RetinaFace,\n\u001b[0;32m     23\u001b[0m     Ssd,\n\u001b[0;32m     24\u001b[0m     Yolo,\n\u001b[0;32m     25\u001b[0m     YuNet,\n\u001b[0;32m     26\u001b[0m     CenterFace,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdemography\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Age, Gender, Race, Emotion\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspoofing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FasNet\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\deepface\\models\\face_detection\\RetinaFace.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mretinaface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RetinaFace \u001b[38;5;28;01mas\u001b[39;00m rf\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDetector\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Detector, FacialAreaRegion\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# pylint: disable=too-few-public-methods\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retinaface\\RetinaFace.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mretinaface\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommons\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m package_utils\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# users should install tf_keras package if they are using tf 2.16 or later versions\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m package_utils\u001b[38;5;241m.\u001b[39mvalidate_for_keras3()\n\u001b[0;32m     22\u001b[0m logger \u001b[38;5;241m=\u001b[39m Logger(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretinaface/RetinaFace.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pylint: disable=global-variable-undefined, no-name-in-module, unused-import, too-many-locals, redefined-outer-name, too-many-statements, too-many-arguments\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# configurations\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retinaface\\commons\\package_utils.py:24\u001b[0m, in \u001b[0;36mvalidate_for_keras3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_keras is already available - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf_keras\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# you may consider to install that package here\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have tensorflow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtf\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and this requires \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf-keras package. Please run `pip install tf-keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor downgrade your tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: You have tensorflow 2.19.0 and this requires tf-keras package. Please run `pip install tf-keras` or downgrade your tensorflow."
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "import pygame\n",
    "import time\n",
    "# Initialize mixer\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.set_volume(0.5)  # Initial volume\n",
    "\n",
    "# Music by emotion\n",
    "emotion_music = {\n",
    "    'happy': 'happy.mp3',\n",
    "    'sad': 'sad.mp3',\n",
    "    'angry': 'angry.mp3',\n",
    "    'surprise': 'surprise.mp3',\n",
    "    'neutral': 'calm.mp3'\n",
    "}\n",
    "\n",
    "# Play music by emotion\n",
    "def play_music(emotion):\n",
    "    if emotion in emotion_music:\n",
    "        pygame.mixer.music.load(emotion_music[emotion])\n",
    "        pygame.mixer.music.play()\n",
    "\n",
    "# Volume control\n",
    "def increase_volume():\n",
    "    vol = pygame.mixer.music.get_volume()\n",
    "    pygame.mixer.music.set_volume(min(1.0, vol + 0.1))\n",
    "    print(f\"Volume up: {pygame.mixer.music.get_volume():.2f}\")\n",
    "\n",
    "def decrease_volume():\n",
    "    vol = pygame.mixer.music.get_volume()\n",
    "    pygame.mixer.music.set_volume(max(0.0, vol - 0.1))\n",
    "    print(f\"Volume down: {pygame.mixer.music.get_volume():.2f}\")\n",
    "\n",
    "# Init\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "drawing = mp.solutions.drawing_utils\n",
    "\n",
    "last_emotion = None\n",
    "last_checked = time.time()\n",
    "cooldown = 5\n",
    "song_changed_on_left = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    h, w, _ = frame.shape\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face in results.multi_face_landmarks:\n",
    "            # Extract landmarks for eyes\n",
    "            left_eye = face.landmark[386]\n",
    "            right_eye = face.landmark[159]\n",
    "\n",
    "            # Convert to pixel coordinates\n",
    "            lx, ly = int(left_eye.x * w), int(left_eye.y * h)\n",
    "            rx, ry = int(right_eye.x * w), int(right_eye.y * h)\n",
    "\n",
    "            cv2.circle(frame, (lx, ly), 4, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, (rx, ry), 4, (255, 0, 0), -1)\n",
    "\n",
    "            # Basic eye raise detection\n",
    "            # If eye is high (lower y-value), consider it \"raised\"\n",
    "            if ly < h * 0.35:\n",
    "                increase_volume()\n",
    "                time.sleep(0.5)\n",
    "            elif ry < h * 0.35:\n",
    "                decrease_volume()\n",
    "                time.sleep(0.5)\n",
    "\n",
    "            # Get face ROI\n",
    "            x_min = min(int(l.x * w) for l in face.landmark)\n",
    "            y_min = min(int(l.y * h) for l in face.landmark)\n",
    "            x_max = max(int(l.x * w) for l in face.landmark)\n",
    "            y_max = max(int(l.y * h) for l in face.landmark)\n",
    "            face_roi = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "            # Face center to detect turn\n",
    "            face_center_x = (x_min + x_max) // 2\n",
    "            frame_center_x = w // 2\n",
    "            face_turn = \"center\"\n",
    "            if face_center_x < frame_center_x - 50:\n",
    "                face_turn = \"left\"\n",
    "            elif face_center_x > frame_center_x + 50:\n",
    "                face_turn = \"right\"\n",
    "\n",
    "            # Emotion detection on cooldown\n",
    "            if time.time() - last_checked >= cooldown:\n",
    "                try:\n",
    "                    result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
    "                    emotion = result[0]['dominant_emotion']\n",
    "                    print(f\"Emotion: {emotion}, Face turned: {face_turn}\")\n",
    "\n",
    "                    if emotion != last_emotion or (face_turn == \"left\" and not song_changed_on_left):\n",
    "                        play_music(emotion)\n",
    "                        last_emotion = emotion\n",
    "                        song_changed_on_left = (face_turn == \"left\")\n",
    "\n",
    "                    last_checked = time.time()\n",
    "                except Exception as e:\n",
    "                    print(\"Emotion detection error:\", e)\n",
    "\n",
    "    cv2.imshow(\"AI Music Controller\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pygame.mixer.music.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fdc941-aa4e-407d-91e6-41a3f121badd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
